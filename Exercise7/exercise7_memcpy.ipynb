{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will implement a recurrent network that operates on a sequence of input values and has to produce a single output value from that sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of our network will be to count how long the input sequence is. For this, we generate a dataset with sequences of random length and with random values. We zero-pad the sequences to be the same length zeros, so that we can perform batching in the data loader. In order for the network to be able to distinguish the padding from the real sequence, we do not allow zeros to occur in the original sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class CpyDataset(Dataset):\n",
    "    def __init__(self, num_samples, N, T):\n",
    "        super(CpyDataset, self).__init__()\n",
    "\n",
    "        def gen_seq():\n",
    "            seq = [random.randint(0, 8) for _ in range(N)]\n",
    "            return {\n",
    "                \"sequence\": torch.as_tensor(seq + [0] * T + [9] * 3 + [0] * N),\n",
    "                \"label\": torch.as_tensor(seq) # the label is just the length of the sequence\n",
    "            }\n",
    "\n",
    "        # generate a bunch of these sequences\n",
    "        self.data = [gen_seq() for _ in range(num_samples)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "N = 5\n",
    "T = 0\n",
    "seq_len = 2*N + T + 3\n",
    "\n",
    "train_data = CpyDataset(20000, N, T)\n",
    "val_data = CpyDataset(3000, N, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network consists of just the RNN, followed by a linear layer to produce the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Regression_RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Regression_RNN, self).__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.rnn = nn.RNN(input_size, self.hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        rnn_out, hidden = self.rnn(sequences)\n",
    "        # Our RNN produces an output value for each input value in the sequence, but we use just the final value for our result\n",
    "        res = self.linear(rnn_out[:, -1])\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_RNN(1, seq_len)\n",
    "model.to(device)\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 0: 100%|██████████| 157/157 [00:00<00:00, 286.02it/s, loss=7.92]\n",
      "val epoch 0: 100%|██████████| 24/24 [00:00<00:00, 573.17it/s, loss=6.7] \n",
      "train epoch 1: 100%|██████████| 157/157 [00:00<00:00, 324.85it/s, loss=6.67]\n",
      "val epoch 1: 100%|██████████| 24/24 [00:00<00:00, 542.97it/s, loss=6.72]\n",
      "train epoch 2: 100%|██████████| 157/157 [00:00<00:00, 323.99it/s, loss=6.67]\n",
      "val epoch 2: 100%|██████████| 24/24 [00:00<00:00, 810.02it/s, loss=6.71]\n",
      "train epoch 3: 100%|██████████| 157/157 [00:00<00:00, 340.12it/s, loss=6.67]\n",
      "val epoch 3: 100%|██████████| 24/24 [00:00<00:00, 819.83it/s, loss=6.7] \n",
      "train epoch 4: 100%|██████████| 157/157 [00:00<00:00, 334.03it/s, loss=6.67]\n",
      "val epoch 4: 100%|██████████| 24/24 [00:00<00:00, 635.57it/s, loss=6.72]\n",
      "train epoch 5: 100%|██████████| 157/157 [00:00<00:00, 323.80it/s, loss=6.67]\n",
      "val epoch 5: 100%|██████████| 24/24 [00:00<00:00, 652.16it/s, loss=6.7] \n",
      "train epoch 6: 100%|██████████| 157/157 [00:00<00:00, 320.93it/s, loss=6.67]\n",
      "val epoch 6: 100%|██████████| 24/24 [00:00<00:00, 767.44it/s, loss=6.7] \n",
      "train epoch 7: 100%|██████████| 157/157 [00:00<00:00, 326.94it/s, loss=6.67]\n",
      "val epoch 7: 100%|██████████| 24/24 [00:00<00:00, 765.64it/s, loss=6.71]\n",
      "train epoch 8: 100%|██████████| 157/157 [00:00<00:00, 322.50it/s, loss=6.67]\n",
      "val epoch 8: 100%|██████████| 24/24 [00:00<00:00, 651.58it/s, loss=6.7] \n",
      "train epoch 9: 100%|██████████| 157/157 [00:00<00:00, 322.02it/s, loss=6.67]\n",
      "val epoch 9: 100%|██████████| 24/24 [00:00<00:00, 749.47it/s, loss=6.7] \n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # perform training followed by validation\n",
    "    for mode, loader in [\n",
    "        (\"train\", train_loader),\n",
    "        (\"val\", val_loader)\n",
    "    ]:\n",
    "        # progressbar setup\n",
    "        num_batches = len(loader)\n",
    "        pbar = tqdm.tqdm(total=num_batches, desc=f\"{mode} epoch {epoch}\")\n",
    "\n",
    "        if mode == \"train\":\n",
    "            model.train() # do calculate gradients for training mode\n",
    "        else:\n",
    "            model.eval() # do not calculate gradients in validation mode\n",
    "\n",
    "        # initial values of the metrics\n",
    "        runningLoss = 0.\n",
    "        correct_predictions = 0\n",
    "        # total number of samples that were processed\n",
    "        total_samples = 0\n",
    "        \n",
    "        # loop over the data\n",
    "        for i_batch, batch in enumerate(loader):\n",
    "            sequences, labels = batch['sequence'], batch['label']\n",
    "            \n",
    "            # move tensors to the correct device\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # convert everything to floats\n",
    "            sequences = sequences.view(*sequences.shape, 1).to(torch.float)\n",
    "            labels = labels.view(*labels.shape, 1).to(torch.float)\n",
    "            \n",
    "            # run the model\n",
    "            predictions = model(sequences)\n",
    "            predictions = torch.narrow(predictions, 1, seq_len-N, N).view(predictions.shape[0], N, 1)\n",
    "            \n",
    "            # loss calculation\n",
    "            loss = mse_loss(predictions, labels)\n",
    "\n",
    "            # calculate the metrics for the progress bar\n",
    "            num_batch_samples = len(sequences)\n",
    "            runningLoss += loss.item() * num_batch_samples\n",
    "            total_samples += num_batch_samples\n",
    "            \n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": runningLoss / total_samples\n",
    "            })\n",
    "\n",
    "            # weight update\n",
    "            if mode == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        epoch_loss = runningLoss / total_samples\n",
    "        if mode == \"train\":\n",
    "            train_losses.append(epoch_loss)\n",
    "        else:\n",
    "            val_losses.append(epoch_loss)\n",
    "\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(train_losses, '--', label=\"training loss\")\n",
    "plt.plot(val_losses, label=\"validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 4, 7, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [2, 3, 2, 4, 7]]\n",
      "[6, 3, 6, 4, 0, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [6, 3, 6, 4, 0]]\n",
      "[8, 0, 1, 8, 1, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [8, 0, 1, 8, 1]]\n",
      "[4, 1, 4, 4, 1, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [4, 1, 4, 4, 1]]\n",
      "[5, 4, 3, 5, 1, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [5, 4, 3, 5, 1]]\n",
      "[3, 6, 6, 4, 1, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [3, 6, 6, 4, 1]]\n",
      "[1, 8, 8, 3, 8, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [1, 8, 8, 3, 8]]\n",
      "[3, 1, 7, 7, 6, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [3, 1, 7, 7, 6]]\n",
      "[3, 8, 4, 3, 0, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [3, 8, 4, 3, 0]]\n",
      "[1, 8, 8, 4, 4, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [1, 8, 8, 4, 4]]\n",
      "[5, 4, 1, 0, 8, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [5, 4, 1, 0, 8]]\n",
      "[3, 1, 6, 7, 0, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [3, 1, 6, 7, 0]]\n",
      "[8, 3, 8, 3, 5, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [8, 3, 8, 3, 5]]\n",
      "[4, 1, 6, 1, 0, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [4, 1, 6, 1, 0]]\n",
      "[6, 1, 5, 3, 2, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [6, 1, 5, 3, 2]]\n",
      "[3, 7, 8, 1, 5, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [3, 7, 8, 1, 5]]\n",
      "[6, 1, 3, 6, 3, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [6, 1, 3, 6, 3]]\n",
      "[6, 3, 6, 8, 8, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [6, 3, 6, 8, 8]]\n",
      "[8, 8, 5, 6, 7, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [8, 8, 5, 6, 7]]\n",
      "[1, 6, 6, 4, 5, 9, 9, 9, 0, 0, 0, 0, 0] -> [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4] [label: [1, 6, 6, 4, 5]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for x in range(20):\n",
    "    sequence, label = val_data[x][\"sequence\"], val_data[x][\"label\"]\n",
    "    \n",
    "    prediction = model(sequence.view(1, -1, 1).to(torch.float).to(device))\n",
    "    \n",
    "    pred_rounded = list(map(lambda x: round(x), prediction.view(-1).tolist()))\n",
    "    \n",
    "    print(f\"{sequence.tolist()} -> {pred_rounded} [label: {label.tolist()}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks for this notebook:\n",
    "\n",
    " - Instead of using nn.RNN, implement the RNN manually according to the lecture slides.\n",
    " \n",
    "## Task: Memory copying\n",
    "In a separate notebook, train an RNN for a different task: Memory copying. For this task, each input sequence consists of the following:\n",
    "   - N random numbers from 0-8, followed by\n",
    "   - T zeros, followed by\n",
    "   - the value 9 three times, followed by\n",
    "   - N zeros\n",
    "   \n",
    "The task of the network is then to generate a sequence of values, which are:\n",
    "   - N+T+3 arbitrary values (not important), followed by\n",
    "   - the same N random numbers from the start of the input sequence.\n",
    "   \n",
    "Some examples for $N=5, T=3$:\n",
    "\n",
    " - Input sequence: [9, 3, 7, 1, 2, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0]\n",
    " - Target sequence: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 3, 7, 1, 2] (0 denotes arbitrary values)\n",
    " - Input sequence: [7, 1, 5, 7, 5, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0]:\n",
    " - Target sequence: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 5, 7, 5] (0 denotes arbitrary values)\n",
    "   \n",
    "The task is thus to \"remember\" the numbers from the start of the sequence, and to produce them when the three nines have been encountered in the input sequence. With the parameter T, the delay until the numbers have to be produced can be amplified. Try out different values of T. For which values of T does the network still converge? Try exchanging nn.RNN for nn.LSTM and see if it can work with higher values of T. What is the reason that the network performance decreases for higher numbers of T?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for $T=0$ the model does not converge, the Loss decreases slightly but not sufficiently. Thus the results are wrong as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
